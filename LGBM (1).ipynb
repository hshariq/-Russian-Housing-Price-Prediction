{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbSDhW3Tsa8dMEOWSje87o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-SVwhBOs6oH","executionInfo":{"status":"ok","timestamp":1701644807745,"user_tz":-300,"elapsed":26922,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}},"outputId":"d8ce2e4f-4f20-4a45-e711-78b4f4cb390f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.feature_selection import SelectKBest, f_regression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","#read csv files in data\n","train = pd.read_csv('/content/drive/MyDrive/data/train.csv')\n","test= pd.read_csv('/content/drive/MyDrive/data/test.csv')"]},{"cell_type":"code","source":["#save row id in a dataframe\n","row_id = test['row ID']\n","#drop it from test now\n","test = test.drop(columns=['row ID'])"],"metadata":{"id":"1D2bfvBmtNHf","executionInfo":{"status":"ok","timestamp":1701644807746,"user_tz":-300,"elapsed":33,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt"],"metadata":{"id":"7z2KcZXktUis","executionInfo":{"status":"ok","timestamp":1701644583040,"user_tz":-300,"elapsed":6,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["#convert data types where coluhmns have values yes and no to 1 and 0\n","train = train.replace({'yes': 1, 'no': 0})\n","test = test.replace({'yes': 1, 'no': 0})\n","\n","#Create an instance of LabelEncoder\n","lbl = LabelEncoder()\n","#do label encoding for prodcut type as well\n","lbl.fit(list(train['product_type'].values) + list(test['product_type'].values))\n","train['product_type'] = lbl.transform(list(train['product_type'].values))\n","test['product_type'] = lbl.transform(list(test['product_type'].values))\n","train.drop(columns=['sub_area'], inplace=True)\n","test.drop(columns=['sub_area'], inplace=True)\n"],"metadata":{"id":"JGIHO0CQ6-eL","executionInfo":{"status":"ok","timestamp":1701644809549,"user_tz":-300,"elapsed":1834,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["categorical_features = train.select_dtypes(include=['object']).columns\n","categorical_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zltDTji73_1","executionInfo":{"status":"ok","timestamp":1701645021584,"user_tz":-300,"elapsed":8,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}},"outputId":"337fd196-1e3a-4424-f203-ea070c6effa8"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index([], dtype='object')"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Assuming lbl is a LabelEncoder instance\n","lbl = LabelEncoder()\n","\n","# Fit the label encoder on the 'ecology' column in the training data\n","lbl.fit(train['ecology'])\n","\n","# Convert the 'ecology' column in the train dataset\n","train['ecology'] = lbl.transform(list(train['ecology'].values))\n","\n","# Convert the 'ecology' column in the test dataset using the same label encoder\n","test['ecology'] = lbl.transform(list(test['ecology'].values))\n"],"metadata":{"id":"4ncblSqV7pX6","executionInfo":{"status":"ok","timestamp":1701645009752,"user_tz":-300,"elapsed":430,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["X = train.drop(columns=['price_doc'])\n","y = train[['price_doc']]"],"metadata":{"id":"n2l4N8YRtLxz","executionInfo":{"status":"ok","timestamp":1701645029990,"user_tz":-300,"elapsed":9,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["import statsmodels.api as sm\n","\n","# Add a constant column to the feature matrix\n","XSM = sm.add_constant(X)\n","\n","# Fit the ordinary least squares (OLS) model\n","model = sm.OLS(train['price_doc'], XSM).fit()\n","\n","# Get the p-values of all columns\n","p_values = model.pvalues\n","\n","# Sort the p-values in ascending order\n","sorted_p_values = p_values.sort_values()\n","\n","# Show only the bottom 35 columns with the lowest p-values\n","bottom_35_p_values = sorted_p_values[:35]\n","\n"],"metadata":{"id":"u58zY4zY85d6","executionInfo":{"status":"ok","timestamp":1701645406231,"user_tz":-300,"elapsed":26454,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["# Get the absolute values of the coefficients as feature importance\n","feature_importance = abs(model.params)\n","\n","# Sort the feature importance in descending order\n","sorted_feature_importance = feature_importance.sort_values(ascending=False)\n","\n","# Show only the top 50 features with the highest importance\n","top_50_features = sorted_feature_importance[:50]\n","\n","# Print the top 50 features\n","# print(top_50_features)\n"],"metadata":{"id":"n-AoFtBrB08H","executionInfo":{"status":"ok","timestamp":1701646414367,"user_tz":-300,"elapsed":6,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["top_50_features.drop('const', inplace=True)\n"],"metadata":{"id":"yIYpyVhlCBfg","executionInfo":{"status":"ok","timestamp":1701646527972,"user_tz":-300,"elapsed":7,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["# Use the bottom 35 features above to train the model\n","\n","# Select the bottom 35 variables from the dataset\n","X_new = X[list(top_50_features.index)]\n","# Do the same for the test dataset as well\n","test_new = test[list(top_50_features.index)]"],"metadata":{"id":"5dgXYLJzB9VG","executionInfo":{"status":"ok","timestamp":1701646533083,"user_tz":-300,"elapsed":450,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","#Create a scaler object\n","scaler = MinMaxScaler()\n","\n","#Fit the scaler and transform X_new\n","X_new = scaler.fit_transform(X)\n","test_new = scaler.fit_transform(test)"],"metadata":{"id":"aNwtcOGi94lp","executionInfo":{"status":"ok","timestamp":1701646544421,"user_tz":-300,"elapsed":2114,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["# Use the bottom 35 features above to train the model\n","\n","# Select the bottom 35 variables from the dataset\n","X_new = X[list(bottom_35_p_values.index)]\n","# Do the same for the test dataset as well\n","test_new = test[list(bottom_35_p_values.index)]"],"metadata":{"id":"u5-CjoBA9_wL","executionInfo":{"status":"ok","timestamp":1701645420715,"user_tz":-300,"elapsed":11,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n","categorical_features = X.select_dtypes(include=['object']).columns\n","#Create transformers for numerical and categorical features\n","numerical_transformer = Pipeline(steps=[\n","    ('scaler', StandardScaler())\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('ordinal', OrdinalEncoder())\n","])\n","\n","# Combine transformers using ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ])\n","\n","# Preprocess the training data\n","X_train_preprocessed = preprocessor.fit_transform(X)\n","X_test_preprocessed = preprocessor.transform(test)"],"metadata":{"id":"4fRaXH0CtXkY","executionInfo":{"status":"ok","timestamp":1701643014719,"user_tz":-300,"elapsed":2975,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["X_train_preprocessed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"crl8zc1o0Dkc","executionInfo":{"status":"ok","timestamp":1701643033829,"user_tz":-300,"elapsed":4,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}},"outputId":"9276d614-4e61-4bab-a426-e11b587eb4f0"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(181507, 271)"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["%pip install catboost\n","%pip install xgboost\n","%pip install lightgbm\n","from catboost import CatBoostClassifier\n","import xgboost as xgb\n","import lightgbm as lgb"],"metadata":{"id":"dec58yhVtbkM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn import tree\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"cMKsk8vctzsQ","executionInfo":{"status":"ok","timestamp":1701643038112,"user_tz":-300,"elapsed":4,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)"],"metadata":{"id":"2ui0mxfTt5s5","executionInfo":{"status":"ok","timestamp":1701646555467,"user_tz":-300,"elapsed":1678,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["# Create LGBMRegressor\n","lgb_model = lgb.LGBMRegressor(n_estimators=700,  # Number of boosting iterations\n","                              learning_rate=0.01,  # Step size shrinkage used in update to prevent overfitting\n","                              max_depth=20,  # Maximum depth of the trees\n","                              objective='regression',  # Loss function for regression\n","                              random_state=2, num_leaves=15)  # Random seed for reproducibility\n","\n","\n","# Fit the model on the training data\n","lgb_model.fit(X_train, y_train)\n","# Make predictions on the test set\n","predictions = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration_)\n","\n","# Evaluate the model\n","mse = mean_squared_error(y_test, predictions)\n","rmse = np.sqrt(mse)\n","print(\"Root Mean Squared Error: %.2f\" % rmse)\n","#  12712668.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5XCTSx1tdOn","executionInfo":{"status":"ok","timestamp":1701647434891,"user_tz":-300,"elapsed":103708,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}},"outputId":"45d1460c-6d85-4773-9789-2cf335487f6f"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.642781 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 65311\n","[LightGBM] [Info] Number of data points in the train set: 145205, number of used features: 270\n","[LightGBM] [Info] Start training from score 14733110.056808\n","Root Mean Squared Error: 12712668.57\n"]}]},{"cell_type":"code","source":["price_doc = lgb_model.predict(test_new)\n"],"metadata":{"id":"o6vPBiENwELP","executionInfo":{"status":"ok","timestamp":1701647464523,"user_tz":-300,"elapsed":5200,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["#Create a DataFrame for the predictions\n","predictions_df = pd.DataFrame(price_doc, columns=['price_doc'])\n","\n","#Add the record ID from the test data to the predictions DataFrame\n","predictions_df.insert(0, 'row ID', row_id)\n","\n","#Save the predictions to a CSV file\n","predictions_df.to_csv('download1me.csv', index=False)"],"metadata":{"id":"7hzpxZ2wzZK4","executionInfo":{"status":"ok","timestamp":1701647465707,"user_tz":-300,"elapsed":1188,"user":{"displayName":"Hamza Shariq","userId":"05395618962528009752"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aVw0tSq-2Kew"},"execution_count":null,"outputs":[]}]}