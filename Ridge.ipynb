{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files in data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test= pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data types where coluhmns have values yes and no to 1 and 0\n",
    "train = train.replace({'yes': 1, 'no': 0})\n",
    "test = test.replace({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import the necessary libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Create an instance of LabelEncoder\n",
    "lbl = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fit the label encoder on the combined data of train and test datasets\n",
    "lbl.fit(list(train['ecology'].values) + list(test['ecology'].values))\n",
    "\n",
    "#Convert the 'ecology' column in the train dataset\n",
    "train['ecology'] = lbl.transform(list(train['ecology'].values))\n",
    "#Convert the 'ecology' column in the test dataset\n",
    "test['ecology'] = lbl.transform(list(test['ecology'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do label encoding for prodcut type as well\n",
    "lbl.fit(list(train['product_type'].values) + list(test['product_type'].values))\n",
    "train['product_type'] = lbl.transform(list(train['product_type'].values))\n",
    "test['product_type'] = lbl.transform(list(test['product_type'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['sub_area'], inplace=True)\n",
    "test.drop(columns=['sub_area'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['price_doc'])\n",
    "y = train[['price_doc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save row id in a dataframe\n",
    "row_id = test['row ID']\n",
    "#drop it from test now\n",
    "test = test.drop(columns=['row ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Fit the scaler and transform X_new\n",
    "testp = scaler.fit_transform(test)\n",
    "Xp = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = scaler.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if X has any null valuesi\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"X has null values\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if X is in range 0 to 1\n",
    "if X_scaled.min(axis=0).sum() < 0 and X_scaled.max(axis=0).sum() > 1:\n",
    "    print(\"X is not in range 0 to 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why is it not being scaled in 0 to 1 range\n",
    "X_scaled = scaler.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", X_scaled.min())\n",
    "print(\"Max:\", X_scaled.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: price_doc    111111112.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Use f_classif (ANOVA F-value method) instead of chi2\n",
    "fvalue_selector = SelectKBest(f_classif, k=30)\n",
    "\n",
    "# Apply the selector to scaled dataset\n",
    "X_kbest = fvalue_selector.fit_transform(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kbest = fvalue_selector.transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 30)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = ['full_sq','life_sq','floor','preschool_education_centers_raion',\n",
    " 'school_education_centers_top_20_raion', 'culture_objects_top_25',\n",
    " 'incineration_raion', 'oil_chemistry_raion', 'big_market_raion',\n",
    " 'nuclear_reactor_raion', 'ekder_female', '16_29_all', '16_29_female',\n",
    " 'build_count_frame', 'build_count_monolith',\n",
    " 'raion_build_count_with_builddate_info', 'build_count_1971-1995',\n",
    " 'green_zone_km', 'industrial_km', 'water_km', 'water_1line',\n",
    " 'big_road1_1line', 'railroad_1line', 'ID_railroad_terminal',\n",
    " 'church_synagogue_km', 'ecology', 'green_part_500', 'prom_part_500',\n",
    " 'trc_sqm_500', 'cafe_count_500_price_1000', 'cafe_count_500_price_1500',\n",
    " 'cafe_count_500_price_high', 'mosque_count_500', 'leisure_count_500',\n",
    " 'market_count_500', 'green_part_1000', 'prom_part_1000', 'office_sqm_1000',\n",
    " 'cafe_count_1000_price_high', 'mosque_count_1000', 'leisure_count_1000',\n",
    " 'market_count_1000', 'office_sqm_1500', 'mosque_count_1500', 'trc_sqm_2000',\n",
    " 'cafe_sum_2000_max_price_avg', 'cafe_count_2000_price_4000',\n",
    " 'mosque_count_2000', 'sport_count_2000', 'trc_sqm_5000']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['full_sq', 'life_sq', 'floor', '16_29_female','build_count_monolith', 'industrial_km', 'church_synagogue_km' , 'prom_part_500'\n",
    "                     , 'trc_sqm_500', 'cafe_count_500_price_high', 'mosque_count_500', 'leisure_count_500', 'market_count_1000', 'green_part_1000'\n",
    "                     , 'office_sqm_1000', 'cafe_count_1000_price_high', 'mosque_count_1000' , 'leisure_count_1000' , 'market_count_1000',  'trc_sqm_2000',\n",
    "                       'sport_count_2000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from X take only the selected features\n",
    "X_selected = X[code]\n",
    "#same for test\n",
    "test_selected = test[code]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant column to the feature matrix\n",
    "XSM = sm.add_constant(train.drop(columns=['price_doc']))\n",
    "\n",
    "# Fit the ordinary least squares (OLS) model\n",
    "model = sm.OLS(train['price_doc'], XSM).fit()\n",
    "\n",
    "# Get the p-values of all columns\n",
    "p_values = model.pvalues\n",
    "\n",
    "# Sort the p-values in ascending order\n",
    "sorted_p_values = p_values.sort_values()\n",
    "\n",
    "# Show only the bottom 35 columns with the lowest p-values\n",
    "bottom_35_p_values = sorted_p_values[:20]\n",
    "\n",
    "# Print the bottom 35 p-values\n",
    "# print(bottom_35_p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "#Select top 30 features\n",
    "selector = SelectKBest(f_regression, k=20)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "X_new = pd.DataFrame(X_new)\n",
    "Xtest = selector.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_sq', 'floor', 'school_education_centers_top_20_raion', 'incineration_raion', 'build_count_monolith', 'raion_build_count_with_builddate_info', 'build_count_1971-1995', 'green_zone_km', 'industrial_km', 'church_synagogue_km', 'green_part_500', 'cafe_count_500_price_high', 'mosque_count_500', 'leisure_count_500', 'green_part_1000', 'office_sqm_1000', 'cafe_count_1000_price_high', 'mosque_count_1000', 'leisure_count_1000', 'sport_count_2000']\n"
     ]
    }
   ],
   "source": [
    "# Get the common columns\n",
    "common_columns = X_selected.columns.intersection(bottom_35_p_values.index)\n",
    "\n",
    "# Convert to list\n",
    "common_columns_list = common_columns.tolist()\n",
    "\n",
    "print(common_columns_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from X take only the selected features\n",
    "fin = X[common_columns_list]\n",
    "#same for test\n",
    "fintest = test[common_columns_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the bottom 35 features above to train the model\n",
    "if 'const' in bottom_35_p_values:\n",
    "    bottom_35_p_values = bottom_35_p_values.drop('const')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Fit the scaler and transform X_new\n",
    "testp = scaler.fit_transform(fintest)\n",
    "Xp = scaler.fit_transform(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 20)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Assume X is your feature matrix\n",
    "selector = VarianceThreshold(threshold=0.06)  # Change threshold value as needed\n",
    "X_high_variance = selector.fit_transform(Xp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181507, 47)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_high_variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testvar=selector.transform(testp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 47)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testvar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the bottom 35 variables from the dataset\n",
    "Xp = train[list(bottom_35_p_values.index)]\n",
    "# Do the same for the test dataset as well\n",
    "testp = test[list(bottom_35_p_values.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# #Create a scaler object\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# #Fit the scaler and transform X_new\n",
    "# testp = scaler.fit_transform(testp)\n",
    "# Xp = scaler.fit_transform(Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X is your feature matrix and y is the target variable\n",
    "# scaler = StandardScaler()\n",
    "# X_std = scaler.fit_transform(Xp)\n",
    "\n",
    "# Define the ridge regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(Xp, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scaler.transform(testp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Xp and testp are the new datasets with only the bottom 35 features\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "X2 = poly.fit_transform(X_kbest)\n",
    "X2_test = poly.transform(test_kbest)\n",
    "print(X2.shape)\n",
    "# print(test.shape)\n",
    "# print(poly.get_feature_names_out())\n",
    "\n",
    "# Create and fit the Ridge regression model\n",
    "ridge = Ridge(alpha=1)  # You can adjust the alpha value as needed\n",
    "ridge.fit(X2, y)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_pred = ridge.predict(X2)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Print the score, coefficients, and intercept of the Ridge model\n",
    "print(\"Score:\", ridge.score(X2, y))\n",
    "print(\"Coefficients:\", ridge.coef_)\n",
    "print(\"Intercept:\", ridge.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+19, tolerance: 8.652e+15\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(2,include_bias=False)\n",
    "X_poly = poly.fit_transform(Xp)\n",
    "X_test=poly.transform(testp)\n",
    "\n",
    "# Define the lasso regression model\n",
    "lasso = Lasso(alpha=1.0)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_poly, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181507, 230)\n",
      "RMSE: 13167111.88900419\n",
      "Score: 0.6362913900959886\n",
      "Coefficients: [[ 8.09227484e+07  1.67535872e+07  3.27703286e+06  5.56569713e+05\n",
      "   6.41760046e+06 -1.37341949e+05 -3.26174573e+05 -1.18387076e+06\n",
      "   8.18690411e+06  4.14957489e+06  5.70521433e+06  8.34624567e+05\n",
      "   2.05508268e+07  7.21864995e+06  7.95937315e+05  9.85977879e+06\n",
      "   1.67655432e+07  4.31916280e+06  8.82530345e+06  1.29970708e+07\n",
      "  -1.77351710e+07 -1.19061756e+07 -3.86175113e+06 -3.42142277e+06\n",
      "  -6.32492135e+06 -1.01714170e+06 -5.36353440e+06 -7.95137249e+06\n",
      "  -6.33237043e+06 -1.20586255e+07 -7.99011407e+06 -3.72239069e+06\n",
      "  -9.67145892e+06 -1.23071890e+07 -1.64855277e+06 -5.14774726e+06\n",
      "  -6.66990604e+06 -7.69263494e+06 -8.20358885e+06  1.00108812e+05\n",
      "   1.14348763e+06 -2.58155349e+06 -1.63696301e+06  2.82420334e+05\n",
      "   9.86933757e+05  3.47960387e+06 -1.57642273e+06 -1.87353668e+06\n",
      "   2.17205396e+05 -2.55178673e+06  3.36101487e+06 -4.59852066e+06\n",
      "  -3.77786824e+06 -4.01791397e+06 -4.16942464e+06 -1.85375498e+06\n",
      "  -1.00063018e+06 -2.90139087e+06  1.41208477e+06  9.73491973e+05\n",
      "   3.58545695e+06 -3.83521525e+05 -1.67192592e+06 -3.21964674e+06\n",
      "   1.53700371e+06  2.72617713e+05  5.95837672e+06 -2.11258659e+06\n",
      "  -1.02926810e+06 -5.45871451e+05  1.13300554e+05  2.40029751e+05\n",
      "  -2.08429294e+06  3.99815814e+06  1.95352180e+05 -3.73289432e+05\n",
      "  -5.43808427e+06  5.56569713e+05  1.51272944e+06  6.07971658e+05\n",
      "  -1.06833725e+06  2.08292271e+05 -1.11325617e+06 -1.65700124e+06\n",
      "  -1.03329802e+06 -1.37016859e+06 -1.35557298e+06  1.42924691e+06\n",
      "  -2.42015182e+05  2.35453375e+06 -8.40045351e+05 -7.21435038e+05\n",
      "   1.62403896e+06  2.30858847e+06 -9.21587058e+05 -4.43888740e+06\n",
      "   7.15546609e+05  7.87637261e+05  3.25535680e+06 -1.30846002e+06\n",
      "   3.25220606e+05 -3.45682722e+05  3.50610246e+04 -5.04955232e+05\n",
      "   2.65357041e+06 -5.47370855e+06 -2.06688437e+06 -3.64247932e+06\n",
      "  -2.25234701e+05  4.78935274e+06  6.16835092e+05 -4.17777525e+06\n",
      "  -1.22708205e+06 -1.12458069e+06  1.18755509e+05  2.17390487e+06\n",
      "  -2.02425956e+06  2.26565965e+06  1.01909974e+07 -3.66973955e+06\n",
      "   1.40122002e+06 -2.28656410e+05  8.48981180e+05 -4.13183420e+06\n",
      "   2.13100697e+06  3.80878211e+05  1.16151234e+06 -2.05701299e+06\n",
      "   1.47968936e+06 -1.64830039e+06  9.90232488e+05 -1.22208783e+05\n",
      "  -1.46921836e+05  4.12123881e+06  2.34002200e+06  3.36431656e+06\n",
      "   7.84606997e+05  3.27087485e+06 -3.24861123e+06  2.74405509e+06\n",
      "  -6.83268357e+05 -6.26470414e+06  5.96103485e+05  3.37881955e+06\n",
      "   2.89895507e+04 -3.24900309e+06  1.65332616e+06  4.49024273e+06\n",
      "  -1.33039241e+06  2.12597924e+06  3.25254993e+06  3.47152980e+06\n",
      "   3.64067867e+06 -5.50085128e+06 -6.92617888e+05 -3.10931671e+05\n",
      "  -2.10100488e+06 -1.50961551e+06 -4.99899919e+06  2.31069288e+06\n",
      "  -1.01252270e+06  1.66263085e+06 -4.26712069e+06  6.42547600e+06\n",
      "   4.76114603e+04 -3.11218317e+06  2.76882867e+06  2.51200451e+06\n",
      "  -3.31564597e+06 -1.99458922e+06 -1.59124597e+05  2.74887749e+06\n",
      "   5.13778457e+06 -3.12270727e+06  9.89030818e+06 -2.49341790e+06\n",
      "  -7.84372143e+05  8.44600204e+05 -2.26791889e+06 -2.51427399e+06\n",
      "   1.27143311e+06  4.61536397e+06  4.75935830e+06  3.37497210e+06\n",
      "   1.78753820e+06  1.78231483e+06  1.07164299e+06  1.49883894e+06\n",
      "   8.93572682e+06 -6.75866569e+06 -4.44922300e+06  4.65027940e+06\n",
      "  -1.26785845e+06 -5.30698239e+06 -6.20904159e+06 -1.00468559e+06\n",
      "   1.04009664e+06  5.65815825e+05 -2.96946547e+06 -1.09782837e+07\n",
      "   1.06190632e+06 -2.35673570e+06  1.65147470e+06  1.57730724e+06\n",
      "  -9.60164991e+05 -3.02784983e+06  2.27791146e+04  1.05363685e+06\n",
      "   3.15221694e+06 -1.85318281e+06  2.90621783e+06 -6.18185588e+05\n",
      "   1.35059480e+06  3.54420738e+05  1.14758305e+06 -2.72734101e+06\n",
      "  -1.15289315e+06  2.38258710e+06  2.03312497e+06 -7.81020014e+06\n",
      "  -2.76454772e+06 -2.38979096e+06 -4.32070165e+06 -7.01055049e+06\n",
      "  -5.63282912e+06  1.29209435e+06  4.13806684e+06  4.29388438e+05\n",
      "  -3.20953004e+06 -1.36950793e+07]]\n",
      "Intercept: [1010374.40240967]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Xp and testp are the new datasets with only the bottom 35 features\n",
    "poly = PolynomialFeatures(2, include_bias=False)\n",
    "X2 = poly.fit_transform(Xp)\n",
    "X2_test = poly.transform(testp)\n",
    "print(X2.shape)\n",
    "# print(test.shape)\n",
    "# print(poly.get_feature_names_out())\n",
    "\n",
    "# Create and fit the Ridge regression model\n",
    "ridge = Ridge(alpha=1)  # You can adjust the alpha value as needed\n",
    "ridge.fit(X2, y)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_pred = ridge.predict(X2)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Print the score, coefficients, and intercept of the Ridge model\n",
    "print(\"Score:\", ridge.score(X2, y))\n",
    "print(\"Coefficients:\", ridge.coef_)\n",
    "print(\"Intercept:\", ridge.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Xp and testp are the new datasets with only the bottom 35 features\n",
    "poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
    "X2 = poly.fit_transform(Xp)\n",
    "X2_test = poly.transform(testp)\n",
    "print(X2.shape)\n",
    "# print(test.shape)\n",
    "print(poly.get_feature_names_out())\n",
    "\n",
    "# Create and fit the Ridge regression model\n",
    "ridge = Ridge(alpha=1.0)  # You can adjust the alpha value as needed\n",
    "ridge.fit(X2, y)\n",
    "\n",
    "# Print the score, coefficients, and intercept of the Ridge model\n",
    "print(ridge.score(X2, y))\n",
    "print(ridge.coef_)\n",
    "print(ridge.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_doc = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_doc = ridge.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_doc = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(price_doc, columns=['price_doc'])\n",
    "\n",
    "#Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'row ID', row_id)\n",
    "\n",
    "#Save the predictions to a CSV file\n",
    "predictions_df.to_csv('Ridge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(price_doc, columns=['price_doc'])\n",
    "\n",
    "#Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'row ID', row_id)\n",
    "\n",
    "#Save the predictions to a CSV file\n",
    "predictions_df.to_csv('lasso.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
